{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we define the variable/parameter $x$. We enable gradient computations\n",
    "for this variable."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "x = torch.tensor(-42., requires_grad=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we create an optimizer that we will use to minimize the loss\n",
    "function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD([x], lr = 0.25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we optimize the loss function $x^2$ until the gradient\n",
    "is less than 1e-5."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: -42, gradient: -84, after:     -21\n",
      "before: -21, gradient: -42, after:     -10\n",
      "before: -10.5, gradient: -21, after:    -5.2\n",
      "before: -5.25, gradient: -10.5, after:    -2.6\n",
      "before: -2.625, gradient: -5.25, after:    -1.3\n",
      "before: -1.3125, gradient: -2.625, after:   -0.66\n",
      "before: -0.65625, gradient: -1.3125, after:   -0.33\n",
      "before: -0.328125, gradient: -0.65625, after:   -0.16\n",
      "before: -0.164062, gradient: -0.328125, after:  -0.082\n",
      "before: -0.0820312, gradient: -0.164062, after:  -0.041\n",
      "before: -0.0410156, gradient: -0.0820312, after:  -0.021\n",
      "before: -0.0205078, gradient: -0.0410156, after:   -0.01\n",
      "before: -0.0102539, gradient: -0.0205078, after: -0.0051\n",
      "before: -0.00512695, gradient: -0.0102539, after: -0.0026\n",
      "before: -0.00256348, gradient: -0.00512695, after: -0.0013\n",
      "before: -0.00128174, gradient: -0.00256348, after: -0.00064\n",
      "before: -0.000640869, gradient: -0.00128174, after: -0.00032\n",
      "before: -0.000320435, gradient: -0.000640869, after: -0.00016\n",
      "before: -0.000160217, gradient: -0.000320435, after:  -8e-05\n",
      "before: -8.01086e-05, gradient: -0.000160217, after:  -4e-05\n",
      "before: -4.00543e-05, gradient: -8.01086e-05, after:  -2e-05\n",
      "before: -2.00272e-05, gradient: -4.00543e-05, after:  -1e-05\n",
      "before: -1.00136e-05, gradient: -2.00272e-05, after:  -5e-06\n",
      "before: -5.00679e-06, gradient: -1.00136e-05, after: -2.5e-06\n",
      "before: -2.5034e-06, gradient: -5.00679e-06, after: -1.3e-06\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    x_before = float(x)\n",
    "\n",
    "    # Clear gradients (set gradients to zero), otherwise gradients\n",
    "    # would be accumulated.\n",
    "    opt.zero_grad()\n",
    "\n",
    "    # Compute our loss function.\n",
    "    loss = x ** 2\n",
    "\n",
    "    # Compute gradients for the parameter(s) for which  we\n",
    "    # enabled gradient computation.\n",
    "    loss.backward()\n",
    "\n",
    "    # Let the optimizer update the parameter(s).\n",
    "    opt.step()\n",
    "\n",
    "    print(f\"before: {x_before:g}, gradient: {x.grad:g}, after: {x:#7.2g}\")\n",
    "\n",
    "    # Stop when the gradient for $x$ is less than 1e-5.\n",
    "    if x.grad.abs() < 1e-5:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}